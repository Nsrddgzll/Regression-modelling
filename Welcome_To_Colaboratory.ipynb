{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurboNeso/Testrepo/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      y : (array_like Shape (m,)) target value \n",
        "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
        "      b : scalar Values of bias parameter of the model\n",
        "      lambda_: unused placeholder\n",
        "    Returns:\n",
        "      total_cost: (scalar)         cost \n",
        "    \"\"\"\n",
        "    # with for loop beginner\n",
        "    m, n = X.shape\n",
        "    cost = 0.0\n",
        "    for i in range(m):\n",
        "        z_wb = 0\n",
        "        for j in range(n):\n",
        "            z_wb_j = w[j]*X[i,j]\n",
        "            z_wb += z_wb_j\n",
        "        z_wb += b\n",
        "        f_wb = sigmoid(z_wb)\n",
        "        loss = -y[i]*np.log(f_wb)-(1-y[i])*np.log(1-f_wb)\n",
        "        cost += loss\n",
        "    total_cost = cost/m\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "exl3WzEKxl4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, w, b, lambda_= 1):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      y : (array_like Shape (m,)) target value \n",
        "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
        "      b : scalar Values of bias parameter of the model\n",
        "      lambda_: unused placeholder\n",
        "    Returns:\n",
        "      total_cost: (scalar)         cost \n",
        "    \"\"\"\n",
        "    # With for loop and vectorization\n",
        "    m, n = X.shape\n",
        "    cost = 0.0\n",
        "    for i in range(m):\n",
        "        z = np.dot(X[i],w) + b\n",
        "        f_wb = sigmoid(z)\n",
        "        cost += -y[i]*np.log(f_wb)-(1-y[i])*(np.log(1-f_wb))\n",
        "    total_cost = cost/m \n",
        "    \n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "0LDvA6fiizUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      y : (array_like Shape (m,)) target value \n",
        "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
        "      b : scalar Values of bias parameter of the model\n",
        "      lambda_: unused placeholder\n",
        "    Returns:\n",
        "      total_cost: (scalar)         cost \n",
        "    \"\"\"\n",
        "    #without for loop (advance)\n",
        "    z = np.dot(X, w) +b\n",
        "    f_wb = sigmoid(z)\n",
        "    \n",
        "    total_cost = (-1/m)*np.sum(y*np.log(f_wb)+(1-y)*np.log(1-f_wb))\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "uUoa6_5CypJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "huqTEVrwymaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: compute_gradient\n",
        "def compute_gradient(X, y, w, b, lambda_=None): \n",
        "    \"\"\"\n",
        "    Computes the gradient for logistic regression \n",
        " \n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) variable such as house size \n",
        "      y : (array_like Shape (m,1)) actual value \n",
        "      w : (array_like Shape (n,1)) values of parameters of the model      \n",
        "      b : (scalar)                 value of parameter of the model \n",
        "      lambda_: unused placeholder.\n",
        "    Returns\n",
        "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
        "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
        "    \"\"\"\n",
        "    \n",
        "    #m, n = X.shape\n",
        "    dj_dw = np.zeros(w.shape)\n",
        "    dj_db = 0.\n",
        "\n",
        "    ### START CODE HERE ### \n",
        "\n",
        "    for i in range(m):\n",
        "        z_wb = 0\n",
        "        for j in range(n):\n",
        "            z_wb_j = w[j]*X[i,j]\n",
        "            z_wb += z_wb_j\n",
        "        z_wb+= b\n",
        "        f_wb = sigmoid(z_wb)\n",
        "        err = f_wb - y[i]\n",
        "        for j in range(n):\n",
        "            dj_dw[j] += err*X[i,j]\n",
        "        dj_db += err\n",
        "    \n",
        "    \"\"\"\"\"\n",
        "   for i in range(m):\n",
        "        z = np.dot(X[i], w)+b\n",
        "        f_wb = sigmoid(z)\n",
        "        err = f_wb -y[i]\n",
        "        for j in range(n):\n",
        "            dj_dw[j]+= err*X[i,j]\n",
        "        dj_db += err\n",
        "    \"\"\"\"\n",
        "    \n",
        "    m = X.shape[0]\n",
        "    z = np.dot(X,w)+b\n",
        "    f_wb = sigmoid(z)\n",
        "    err = f_wb-y\n",
        "    \n",
        "    dj_dw = (1/m)*np.dot(X.T, err)\n",
        "    dj_db = (1/m)*np.sum(err)\n",
        " \n",
        "            \n",
        "    dj_dw /= m\n",
        "    dj_db /= m\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "        \n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "QJ7_aQKlrGzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}